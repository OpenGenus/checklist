# Data Science Checklist: 10 Weeks Free Bootcamp

Only concepts that you need to review to ace your Data Science Interview

**Week 1: Basics**
==============
1. **Introduction to Data Science**<br>  Data Science is an interdisciplinary field [ related to many other emerging fields](https://iq.opengenus.org/relation-of-data-science/) and has [ different phases](https://iq.opengenus.org/phases-of-data-science/) involved.
2. **Mathematics for Data Science**<br>  Mathematics is widely used in Data Science.  [This article](https://iq.opengenus.org/mathematics-for-data-science/) gives us an overview of the few topics of mathematics that are profusely used.
3. **Over and under sampling**<br>  [Over and under sampling](https://iq.opengenus.org/over-and-under-sampling/) are two ways to randomly sample an imbalanced dataset to make it balanced.
4. **Supervised, Unsupervised and Semi-Supervised Learning**<br>  In machine learning, the tasks are broadly categorized into [supervised,unsupervised and semi-supervised learning](https://iq.opengenus.org/supervised-unsupervised-and-semi-supervised-learning/) which forms the foundation of our understanding of machine learning.
5. **Neural Network and Deep learning**<br>  Deep learning is a subset of machine learning. It extensively uses [neural networks](https://iq.opengenus.org/neural-network/) to imitate the learning techniques of the human brain. There are different types of [neural networks](https://iq.opengenus.org/neural-network/) available.
6. **Beginner's Guide to Google Colaboratory**<br>  [Google colaboratory](https://iq.opengenus.org/google-colab/)  is a free, web-based Jupyter notebook environment. It allows you to write and execute Python code, document your code using Markdown, visualize datasets, and is an excellent tool for data scientists.
7. **Data analysis tools**<br>  The process of [Data analysis](https://iq.opengenus.org/data-analysis-tools/)  is the process of collection, organization, transformation and modeling of data to draw conclusions, make predictions and also make informed decisions. Data scientists mostly use [python for data analysis](https://iq.opengenus.org/python-for-data-analysis/) and also other tools like [tableau ](https://iq.opengenus.org/data-visualization-using-tableau/) for visualization.

**Week 2: Machine Learning Basics**
===============================
1. **Feature engineering**<br>  Feature engineering is done is to make data better for the problem you are trying to solve using machine learning. [ LASSO](https://iq.opengenus.org/feature-selector-using-lasso/) is a popular technique used to select features.
2. **Regularization**<br>  [Regularization](https://iq.opengenus.org/regularization/) is a method used to reduce the variance of your model and increase the bias. [L1 and L2 regularizations](https://iq.opengenus.org/l1-and-l2-regularization-methods/) are some of the widely used techniques. However, it is [ different ](https://iq.opengenus.org/standardization-regularization-vs-normalization/) from other techniques like standardization.
3. **Frequently used terminologies**<br>  Some of the frequently used terms in ML are [normalization](https://iq.opengenus.org/normalization-in-detail/), [latency](https://iq.opengenus.org/latency-ml/), [throughput](https://iq.opengenus.org/throughput-ml/), [quantization](https://iq.opengenus.org/basics-of-quantization-in-ml/), [pruning](https://iq.opengenus.org/pruning-in-ml/), [bias](https://iq.opengenus.org/bias-machine-learning/) and [early stopping.](https://iq.opengenus.org/early-exit-in-ml-models/)
4. **Model evaluation**<br>  In machine learning, [model evaluation](https://iq.opengenus.org/model-evaluation/) is used to find the algorithm is best suited to solve our problem. It is done by calculating the [performance metrics](https://iq.opengenus.org/performance-metrics-in-classification-regression/); some of which are [precision, recall, sensitivity and specificity](https://iq.opengenus.org/precision-recall-sensitivity-specificity/).
5. **Hyperparameters**<br>  Hyperparameters express “higher-level” properties of the model such as its complexity or how fast it should learn and are usually fixeed before training. [Learning rate ](https://iq.opengenus.org/learning-rate/) is an example. [Hyperparameter tuning](https://iq.opengenus.org/different-hyperparameter-optimization-techniques/) is choosing a set of optimal hyperparameters for a learning algorithm.
6. **Gradient descent**<br>  [Gradient Descent ](https://iq.opengenus.org/gradient-descent/) is an essential optimization algorithm that helps us finding optimum parameters of our machine learning models. It has different [types ](https://iq.opengenus.org/types-of-gradient-descent/) of which [stochastic gradient descent ](https://iq.opengenus.org/stochastic-gradient-descent-sgd/) is widely used. The reverse process is called [ gradient ascent ](https://iq.opengenus.org/gradient-ascent/).
7. **Ensemble methods**<br>  [Ensemble methods](https://iq.opengenus.org/ensemble-methods-machine-learning/) combines predictions from several models into a single one. [Boosting](https://iq.opengenus.org/boosting-ensemble-algorithm/), [stacking](https://iq.opengenus.org/stacking-in-machine-learning/) and [voting classifier](https://iq.opengenus.org/voting-classifier/) are some ensembling techniques.

**Week 3: Classification**
======================
1. **Classification**<br>  Classification is categorizing data into different classes. This is based on making predictions using past examples. We feed some examples where we know what the correct prediction is into the model and the model learns from these examples to make accurate predictions in the future.
2. **Logistic Regression**<br>  Logistic Regression is an efficient algorithm that aims to predict categorical values, often binary.It has its own  [ advantages & disadvantages](https://iq.opengenus.org/advantages-and-disadvantages-of-logistic-regression/). It can be implemented using [ scikit learn](https://iq.opengenus.org/logistic-regression-using-scikit-learn/) and [ tensorflow](https://iq.opengenus.org/logistic-regression-tensorflow-python/).
3. **K-Nearest Neighbours**<br>  [K-Nearest Neighbours](https://iq.opengenus.org/k-nearest-neighbors-algorithm/) is an algorithm which is used for classification and regression and is based on the idea of considering the nearest K data points for calculations.  [This example](https://iq.opengenus.org/text-classification-using-k-nearest-neighbors/) uses KNN for text classification.
4. **Decision tree**<br>  [Decision tree](https://iq.opengenus.org/decision-trees/) is a popular machine learning algorithm mainly used for classification. Usually, [ID3 algorithm](https://iq.opengenus.org/id3-algorithm/) is used to build a decision tree.
5. **Support Vector Machine**<br>  [SVMs](https://iq.opengenus.org/understand-support-vector-machine-in-depth/) are a particularly powerful and flexible class of supervised algorithms for both classification and regression. It has many [advantages](https://iq.opengenus.org/advantages-of-svm/) and [applications](https://iq.opengenus.org/applications-of-svm/). It can be easily [implemented](https://iq.opengenus.org/svm-by-improving-classifier/)

**Week 4: Regression**
==================
1. **Regression**<br>  [Regression](https://iq.opengenus.org/regression-used-in-data-science/)is a statistical method used in various fields to find out how strong the relationship between a dependent variable and one or more independent variable is.
2. **Linear Regression**<br>  Linear Regression is regression technique modelling relationship between dependent variable and one or more independent variables by using a linear approach. It has its own  [ advantages & disadvantages](https://iq.opengenus.org/advantages-and-disadvantages-of-linear-regression/). It can be implemented using [ scikit learn](https://iq.opengenus.org/linear-regression-using-scikit-learn/) and [ tensorflow](https://iq.opengenus.org/linear-regression-tensorflow-python/).
3. **Random forest**<br>  [Random forest](https://iq.opengenus.org/random-decision-forest/) are an ensemble learning method for classification and regression.  It has various [applications](https://iq.opengenus.org/applications-of-random-forest/). [This example](https://iq.opengenus.org/random-forests-using-scikit-learn/) uses random forest for regression.
4. **Polynomial regression**<br>  [Polynomial regression](https://iq.opengenus.org/polynomial-regression-using-scikit-learn/) is a form of linear regression in which the relationship between the independent variable x and dependent variable y is not linear but it is the nth degree of polynomial.
5. **Elastic Net regression**<br>  Elastic Net regression uses [Elastic Net regularization](https://iq.opengenus.org/elastic-net-regularization/).
6. **Ridge and Lasso regression**<br>  [Ridge](https://iq.opengenus.org/ridge-regression/) and LASSO regressions use L2 and L1 regularizations that we saw previously.
7. **Data analysis using regression techniques**<br>  [This article](https://iq.opengenus.org/data-analysis-using-regression/) explains how regression analysis is done.

**Week 5: Unsupervised learning**
=============================
1. **K-means clustering**<br>  K-means clustering is a prime example of unsupervised learning and partitional clustering. An improved version of this is  [ K+ means clustering algorithm](https://iq.opengenus.org/k-plus-means-algorithm/).
2. **DBSCAN clustering**<br>  [DBSCAN clustering](https://iq.opengenus.org/dbscan-clustering-algorithm/) is a density-based clustering that identify clusters in the dataset by finding regions which are more densely populated than others.
3. **Spectral clustering**<br>  [Spectral clustering](https://iq.opengenus.org/spectral-clustering/) is a technique with roots in graph theory, where the approach is used to identify communities of nodes in a graph based on the edges connecting them.
4. **Apriori algorithm**<br>  [Apriori algorithm](https://iq.opengenus.org/apriori-associative-learning/) is a associative learning algorithm which is generally used in data mining.
5. **Manifold learning**<br>  [Manifold learning](https://iq.opengenus.org/manifold-learning/) is the process of modeling manifolds where the data lies. It is a technique used for dimensionality reduction.
6. **Principal component analysis**<br>  [Principal component analysis](https://iq.opengenus.org/algorithm-principal-component-analysis-pca/) is a technique to bring out strong patterns in a dataset by supressing variations. You can check out [why PCA works](https://https://iq.opengenus.org/why-principal-component-analysis-pca-works/) to get a basic idea behind its working. [KPCA](https://iq.opengenus.org/kernal-principal-component-analysis/) is a variant of PCA.

**Week 6: Deep Learning**
=====================
1. **Different layers and activation functions**<br>  There are [many different layers ](https://iq.opengenus.org/purpose-of-different-layers-in-ml/) in a deep learning model like [fully connected layer ](https://iq.opengenus.org/fully-connected-layer/) . [Hidden layers ](https://iq.opengenus.org/hidden-layers/) are the most intriguing ones. We also have certain [activation functions](https://iq.opengenus.org/types-of-activation-function//) that decides the state of the neuron.
2. **Top Deep learning frameworks**<br>  [Top deep learning frameworks](https://iq.opengenus.org/top-deep-learning-frameworks/) include Tensorflow, Keras, Caffe2, PyTorch and many more.
3. **Commonly Used Neural Networks**<br>  [Commonly Used Neural Networks](https://iq.opengenus.org/commonly-used-neural-networks/) include various networks such as [RBFNN](https://iq.opengenus.org/radial-basis-neural-network/), [KNN](https://iq.opengenus.org/kohonen-network/) and [Hopfield Network
](https://iq.opengenus.org/hopfield-network/).
4. **CNN models**<br>  The CNN  [models have evolved](https://iq.opengenus.org/evolution-of-cnn-architectures/) and some of the [commonly used models now](https://iq.opengenus.org/different-types-of-cnn-models/) include [AlexNet](https://iq.opengenus.org/architecture-and-use-of-alexnet/), [ ResNet ](https://iq.opengenus.org/resnet/), [ GoogleNet ](https://iq.opengenus.org/googlenet/), [ Xception ](https://iq.opengenus.org/xception-model/), [ DenseNet ](https://iq.opengenus.org/architecture-of-densenet121/) and many more. CNNs are also widely used in  [ image recognition and classification ](https://iq.opengenus.org/understanding-convolutional-neural-networks-through-image-classification/).
5. **Data Augmentation**<br>  [Data Augmentation](https://iq.opengenus.org/data-augmentation/), is the technique of increasing the size of data used for training a model.
6. **GAN**<br>  [Generative Adversarial Networks](https://iq.opengenus.org/beginners-guide-to-generative-adversarial-networks/) is an architecture for training a generative model. There are many  [ types of GANs](https://iq.opengenus.org/types-of-gans/) like [ SRGAN](https://iq.opengenus.org/super-resolution-gan/), [ Deep convolutional GAN](https://iq.opengenus.org/deep-convolutional-gans-pytorch/), [ CycleGANs](https://iq.opengenus.org/image-to-image-translation-cyclegan/) and [ Conditional GAN](https://iq.opengenus.org/conditional-generative-adversarial-net/ target=).
7. **Inception models**<br>  [Inception architecture](https://iq.opengenus.org/inception-pre-trained-cnn-model/) is an important milestone in the development of CNN classifiers. It consists of many architectures like [Inception-ResNet V1](https://iq.opengenus.org/inception-resnet-v1/), [Inception V3](https://iq.opengenus.org/inception-v3-model-architecture/) and [Inception V4](https://iq.opengenus.org/inception-v4-architecture/).
8. **VGG models**<br>  VGG came into picture as it addresses the depth of CNNs. It consists of many architectures like [VGG-11](https://iq.opengenus.org/vgg-11/), [VGG-19](https://iq.opengenus.org/vgg19-architecture/) and [VGG-16](https://iq.opengenus.org/vgg16/).
9. **Boltzmann Machines**<br>  [Boltzmann Machines](https://iq.opengenus.org/boltzmann-machines/) are models used to discover features in datasets composed of binary vectors. A  [Restricted Boltzmann Machine](https://iq.opengenus.org/restricted-boltzmann-machine/) is a variant in which a visible node is not connected to any other visible node and is used in  [deep belief networks](https://iq.opengenus.org/deep-belief-network/).
10. **YOLO**<br>  [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/) is a object detection algorithm that has variants like, [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/)v3, [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/)v4, Scaled [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/)v4, [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/)R and [YOLO](https://iq.opengenus.org/you-look-only-once-yolo-algorithm/)v5.
11. **SSD**<br>  [Single shot detection](https://iq.opengenus.org/single-shot-detection-ssd-algorithm/) is an object detection algorithm and it's [architecture](https://iq.opengenus.org/ssd-model-architecture/) is a modified version of VGG. It is used in  [SSD MobileNetV1](https://iq.opengenus.org/ssd-mobilenet-v1-architecture/) and [RefineDet model](https://iq.opengenus.org/refinedet/) .

**Week 7: NLP**
===========
1. **Introduction**<br>  [NLP ](https://iq.opengenus.org/use-of-deep-learning-in-nlp/)  refers to the ability of the computers to understand human speech or text as it is spoken or written. Some [ core topics are listed here](https://iq.opengenus.org/nlp-topics-with-nltk/). [TF-IDF ](https://iq.opengenus.org/tf-idf/) is an important metric used in [NLP ](https://iq.opengenus.org/use-of-deep-learning-in-nlp/)mostly used to [find similarities between documents](https://iq.opengenus.org/document-similarity-tf-idf/) .
2. **NLP models**<br>  There are different [types of NLP models](https://iq.opengenus.org/types-of-nlp-models/) present. Some of them are [BERT](https://iq.opengenus.org/bert-for-text-summarization/), [GPT](https://iq.opengenus.org/introduction-to-gpt-models/), XLNet, Ro[BERT](https://iq.opengenus.org/bert-for-text-summarization/)a and AL[BERT](https://iq.opengenus.org/bert-for-text-summarization/).
3. **Text Preprocessing**<br>  [Text preprocessing](https://iq.opengenus.org/commonly-used-neural-networks/) process of converting a human language text into a machine-interpretable text for further usage. [Stemming (Porter Stemmer algorithm)](https://iq.opengenus.org/porter-stemmer/) is an example.
.
4. **Text summarization**<br>  [Text summarization](https://iq.opengenus.org/text-summarization-techniques/) is the process of creating a compact yet accurate summary of text documents. Some techniques include [Luhn's Heuristic Method](https://iq.opengenus.org/luhns-heuristic-method-for-text-summarization/), [Edmundson Heuristic Method](https://iq.opengenus.org/edmundson-heuristic-method-for-text-summarization/), [ SumBasic algorithm ](https://iq.opengenus.org/sumbasic-algorithm-for-text-summarization/), [ KL-Sum](https://iq.opengenus.org/k-l-sum-algorithm-for-text-summarization/), [ LexRank ](https://iq.opengenus.org/lexrank-text-summarization/), [ TextRank ](https://iq.opengenus.org/textrank-for-text-summarization/), [ Reduction ](https://iq.opengenus.org/graph-based-approach-for-text-summarization/), [ Latent Semantic Analysis](https://iq.opengenus.org/latent-semantic-analysis-for-text-summarization/) and [ use of RNN](https://iq.opengenus.org/text-summarization-using-rnn/).
5. **Topic Modelling**<br>  There are [different techniques](https://iq.opengenus.org/topic-modelling-techniques/) for topic modelling. Some include [Latent Dirichlet Allocation ](https://iq.opengenus.org/latent-dirichlet-allocation/), [Non Negative Matrix Factorization](hhttps://iq.opengenus.org/topic-modeling-nmf/), [Pachinko Allocation Model](https://iq.opengenus.org/pachinko-allocation-model//) and  [Latent Semantic Analysis](https://iq.opengenus.org/topic-modeling-lsa/#:~:text=Latent%20Semantic%20Model%20is%20a,from%20the%20corpus%20of%20text.).
6. **Information Retrieval**<br>  Information Retrieval can be defined as finding material of an unstructured nature that satisfies the information need from within large collections. It uses the concept of [indexing ](https://iq.opengenus.org/idea-of-indexing-in-nlp/). [ PageRank algorithm](https://iq.opengenus.org/pagerank/) is used to rank web pages used for Google Search Engine.
7. **Sentiment analysis**<br>  There are  [various techniques](https://iq.opengenus.org/sentiment-analysis-techniques/) to perform sentiment analysis. Using [Naive Bayes classifier](https://iq.opengenus.org/naive-bayes-sentiment-analysis/), [Lexicon-based techniques](https://iq.opengenus.org/lexicon-based-sentiment-analysis/), [ML approaches](https://iq.opengenus.org/ml-for-sentiment-analysis/) and [LSTM](https://iq.opengenus.org/sentiment-analysis-in-lstm-keras/) are some of them.
8. **Miscellaneous**<br>  Some other important topics in NLP are  [document clustering](https://iq.opengenus.org/document-clustering-nlp-kmeans/), [language identification techniques](https://iq.opengenus.org/language-identification-techniques/), [spell correction](https://iq.opengenus.org/different-spell-correction-techniques-in-nlp/), [word embedding](https://iq.opengenus.org/word-embedding/), [word representations](https://iq.opengenus.org/word-representations/) and [byte pair encoding](https://iq.opengenus.org/byte-pair-encoding/).

**Week 8: Time series**
===================
1. **Introduction to Time Series Data**<br>  In  [time series data](https://iq.opengenus.org/time-series-data/) we have a collection of observations of a single entity at different time intervals. Weather records, economic indicators and patient health evolution metrics — all are [time series data](https://iq.opengenus.org/time-series-data/).
2. **Basics of Time Series Prediction**<br>  [Time series prediction](https://iq.opengenus.org/time-series-prediction/) involves concepts like stationarity, moving averages, seasonality and many more which you should be familiar with in order to better understand time series forecasting.
3. **Time series forecasting models and techniques**<br>  Future trend prediction is made by discovering and analyzing underlying patterns in the time series data. Various [methods and models](https://iq.opengenus.org/time-series-analysis-methods/) are used for the same.
4. **Time series prediction techniques**<br>  Various artificial neural network models are put to use when performing a time series prediction. [This article](https://iq.opengenus.org/time-series-prediction-techniques/) elaborates on a few models.
5. **Time series forecasting-Example**<br>  This is an [example of time series forecasting](https://iq.opengenus.org/time-series-forecasting-using-python/) where we put into use the techniques we saw in the previous articles.

**Week 9: Statistics and probability**
==================================
1. **Statistical features**<br>  In  [Statistical features](https://iq.opengenus.org/statistical-features/) are those features of the dataset that can be defined and calculated via statistical analysis. It is the statistical concept that is probably most used in data science.
2. **Types of hypotheses**<br>  A hypothesis is a precise, testable statement of what a researcher predicts will be the outcome of an experiment or study. There are  [different types of hypotheses](https://iq.opengenus.org/different-types-of-hypothesis/) that are widely used.
3. **Hypothesis testing**<br>  [Hypothesis testing](https://iq.opengenus.org/hypothesis-testing/) is used to determine whether there is enough evidence to infer for a certain sample that a certain condition is true for the entire population. [ F Test](https://iq.opengenus.org/f-test/) is one such hypothesis test.
4. **CLT and LLN**<br>  [Central limit theorem](https://iq.opengenus.org/central-limit-theorem/#:~:text=It%20states%20that%20%22As%20the,greater%20than%2030%20are%20considered.) and [Law of large numbers](https://iq.opengenus.org/law-of-large-numbers/) are the two important statistical rules that's often put to use in Data Science.
5. **Confidence intervals**<br>  [Confidence intervals](https://iq.opengenus.org/confidence-intervals/) expresses a range of values within which we are pretty sure that the population parameter lies.
6. **Bayesian model**<br>  A [Bayesian model](https://iq.opengenus.org/bayesian-model/) is a statistical model where we use probability to represent all uncertainty within the model, both the uncertainty regarding the output but also the uncertainty regarding the input to the model.
7. **Markov model**<br>  A [Markov chain](https://iq.opengenus.org/markov-chain/) is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Another variant of this is the [hidden markov model](https://iq.opengenus.org/hidden-markov-model/).
8. **A/B testing**<br>  [A/B testing](https://iq.opengenus.org/a-b-testing/) is a famous testing technique used to compare two variants to determine the best of the two based on user experience. It is a randomized experimentation process.
9. **Simulated annealing**<br>  [Simulated annealing ](https://iq.opengenus.org/simulated-annealing/)is a algorithm used in probability based on the physical annealing process used in metallurgy.
10. **Monte carlo sampling techniques**<br>  [Monte Carlo techniques ](https://iq.opengenus.org/monte-carlo-sampling-techniques/) are a group of computational algorithms for sampling probability distributions in a random manner.

**Week 10: Projects**
=================
1. **Project ideas**<br>  In  [This article](https://iq.opengenus.org/project-ideas-for-data-science/) contains a list of unique data science project ideas that you can explore.
2. **Face recognition**<br>  Face recognition can be implemented in python using [Eigenfaces](https://iq.opengenus.org/eigenfaces-for-face-recognition/) or [Fisherfaces](https://iq.opengenus.org/face-recognition-using-fisherfaces/).
3. **Fraud detection**<br>  [Fraud detection](https://iq.opengenus.org/fraud-detection-using-keras/) is the process of detecting fraudulent feats in credit card transactions and can be classified into anomaly detection.
4. **Native Language Identification**<br>  [Native language identification](https://iq.opengenus.org/native-language-identification-dl/) is the task of determining an author's native language based only on their writings or speeches in a second language.
5. **Person re-identification**<br>  [Person re-identification](https://iq.opengenus.org/person-reidentification/) is the task of using a picture of a person to identify the presence of the same person is a set of images or video. It is used to identify a person in a CCTV footage.
6. **Hindi Optical Character Recognition**<br>  [Hindi OCR ](https://iq.opengenus.org/hindi-ocr/) is basically a model which is used to recognize handwritten Hindi (Devanagari) characters.
7. **Face reconstruction**<br>  In [this project](https://iq.opengenus.org/project-on-reconstructing-face/) we find the set of faces when combined, resulting in face of person 'A' using machine learning techniques like PCA, face reconstruction and much more.

**Practice interview questions**
============================
1. **Basic data science questions**<br>  [This article](https://iq.opengenus.org/interview-questions-on-data-science/) contains a list of basic data science interview questions.
2. **Advanced data science questions**<br>  [This article](https://iq.opengenus.org/advanced-interview-questions-on-data-science/) contains a list of advanced data science interview questions.
3. **Python**<br>  [Python](https://iq.opengenus.org/python-for-data-science-interview-questions/) is the most-tested programming language during data science interviews.
4. **Machine learning**<br>  Knowledge on various ML topics such as [TensorFlow (basic level)](https://iq.opengenus.org/questions-on-tensorflow/), [TensorFlow (advanced level)](https://iq.opengenus.org/advanced-questions-on-tensorflow/), [convolution](https://iq.opengenus.org/questions-on-convolution-in-ml/), [regression](https://iq.opengenus.org/regression-questions/), [random forest](https://iq.opengenus.org/questions-on-random-forest/) and [PCA](https://iq.opengenus.org/principal-component-analysis-questions/)  are widely tested.
5. **Deep learning**<br>  [Deep learning ](https://iq.opengenus.org/deep-learning-practice-questions/) topics such as [RNN ](https://iq.opengenus.org/recurrent-neural-network-questions/), [fully connected layer ](https://iq.opengenus.org/fully-connected-layer-questions/), [convolution layer ](https://iq.opengenus.org/convolution-layer-questions/), [GAN ](https://iq.opengenus.org/interview-questions-on-gan/) and [autoencoders ](https://iq.opengenus.org/interview-questions-on-autoencoders/) are frequently tested.
6. **NLP**<br>  NLP topics such as [text summarization ](https://iq.opengenus.org/interview-questions-on-text-summarization/), [transformers ](https://iq.opengenus.org/interview-questions-on-transformers/) and [BERT ](https://iq.opengenus.org/bert-interview-questions/) are important for interviews.

---
Generated by OpenGenus. Updated on 2023-11-27